{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyksc import ksc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME='/home/wagnernegrao/Downloads/dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv(FILENAME, usecols=['Date', 'Project', \n",
    "                                    'code', 'filename', 'language'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes dirt from the Date column \n",
    "df['Date'] = df.Date.apply(lambda date: date.replace('.csv', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# sort column\n",
    "df = df.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only the languages that are being used\n",
    "df = df.loc[(df['language']  == 'C') |\n",
    "              (df['language'] == 'C++') |\n",
    "              (df['language'] == 'C#') |\n",
    "              (df['language'] == 'Clojure') |\n",
    "              (df['language'] == 'CoffeeScript') |\n",
    "              (df['language'] == 'Go') |\n",
    "              (df['language'] == 'Haskell') |\n",
    "              (df['language'] == 'Java') |\n",
    "              (df['language'] == 'JavaScript') |\n",
    "              (df['language'] == 'Kotlin') |\n",
    "              (df['language'] == 'Lua') |\n",
    "              (df['language'] == 'Objective C') |\n",
    "              (df['language'] == 'PHP') |\n",
    "              (df['language'] == 'Python') |\n",
    "              (df['language'] == 'Ruby') |\n",
    "              (df['language'] == 'Rust') |\n",
    "              (df['language'] == 'Scala') |\n",
    "              (df['language'] == 'Swift') |\n",
    "              (df['language'] == 'TypeScript') |\n",
    "              (df['language'] == 'Elixir')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_unique(dfx):\n",
    "    \"\"\"\n",
    "    Cria uma lista com arquivos unicos e remove os arquivos repetidos\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    object dfx: recebe um dataset\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    list files: lista com os arquivos unicos\n",
    "    \"\"\"\n",
    "    \n",
    "    files_list = dfx.filename.tolist()\n",
    "\n",
    "    files = []\n",
    "\n",
    "    for i in files_list:\n",
    "        if(i not in files):\n",
    "            files.append(i)\n",
    "    \n",
    "    return(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra o dataframe para apenas arquivos acima do limiar\n",
    "dfx = df.loc[df['code'] >= 13196]\n",
    "\n",
    "\n",
    "unique_files = file_unique(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Quantidade de arquivos unicos: ', 502)\n"
     ]
    }
   ],
   "source": [
    "print(\"Quantidade de arquivos unicos: \", len(unique_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(df, unique_files):\n",
    "    '''\n",
    "    Cria um dataframe para cada arquivo unico e adiciona numa lista. \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    object df: Dataset\n",
    "    list unique_files: Lista com os arquivos unicos\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    list dfs: Uma lista com varios dataframes\n",
    "    '''\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    for path in unique_files:\n",
    "         dfs.append(df.loc[df['filename'] == path])\n",
    "    \n",
    "    return(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wagnernegrao/Virtualizations/largeFiles_py2/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Torna float a coluna code\n",
    "dfx['code'] = dfx.code.apply(lambda code: float(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = create_dataframe(dfx, unique_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_series(dfs):\n",
    "    '''\n",
    "    Percorre cada dataframe da lista e adiciona o LOC\n",
    "    e os anos de cada um em uma lista.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    object dfs: Lista com dataframes\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    list tm_series: Lista com o LOC de cada arquivo\n",
    "    list years: Lista com os anos de cada arquivo\n",
    "    '''\n",
    "    \n",
    "    time_series = [] \n",
    "    years = [] \n",
    "    \n",
    "    for df in dfs:\n",
    "        time_series.append(df.code.tolist())\n",
    "        years.append(df.Date.dt.year.tolist())\n",
    "        \n",
    "    return(time_series, years)\n",
    "\n",
    "\n",
    "loc_list, years = create_series(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Media de LOC:', 31)\n",
      "('Mediana de LOC:', 9.0)\n"
     ]
    }
   ],
   "source": [
    "import statistics as stacs\n",
    "\n",
    "# Cria a media e a mediana\n",
    "\n",
    "value_sum = 0\n",
    "value_list = []\n",
    "\n",
    "for i in loc_list:\n",
    "    value_sum+=len(i)\n",
    "    value_list.append(len(i))\n",
    "    \n",
    "value_list = sorted(value_list)\n",
    "\n",
    "min_value = value_sum/len(loc_list)\n",
    "\n",
    "print(\"Media de LOC:\", value_sum/len(loc_list))\n",
    "print(\"Mediana de LOC:\", stacs.median(value_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usado para deixar as listas com o mesmo tamanho \n",
    "\n",
    "def size_series(loc_list, min_value):\n",
    "    \n",
    "    \"\"\"\n",
    "    Verifica as listas que possuem o tamanho menor que o valor minimo\n",
    "    e remove, apos isso deixa todas as listas com o mesmo tamanho\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    list loc_list: Lista com todos os LOC dos arquivos\n",
    "    int min_value: Valor minimo para tamanho das listas\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    list loc_list: Nova lista de LOC\n",
    "    int min_value: Novo valor minimo\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    flag = False\n",
    "\n",
    "    while(flag != True):\n",
    "        \n",
    "        for i in range(len(loc_list)):\n",
    "            \n",
    "            if(len(loc_list[i]) < min_value):\n",
    "                loc_list.pop(i)\n",
    "                break\n",
    "\n",
    "            for j in range(len(loc_list[i])):\n",
    "                if(j >= min_value):\n",
    "                    loc_list[i].pop(j)\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "        for serie in loc_list:\n",
    "            if(len(serie) == min_value):\n",
    "                flag = True\n",
    "            else:\n",
    "                flag = False\n",
    "                break\n",
    "        \n",
    "    # para todas s√©ries iniciarem em zero, como sendo a criacao do arquivo\n",
    "    for serie in loc_list:\n",
    "        serie.insert(0,0)\n",
    "        \n",
    "    return(loc_list, min_value+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_loc_list, new_min_value = size_series(loc_list, min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_year_serie(min_value, years):\n",
    "    \"\"\"\n",
    "    Cria uma lista com a quantidade de anos, apos isso adiciona\n",
    "    novamente cada ano ate a lista ter o tamanho necessario\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    int min_value: Valor minimo para tamanho da lista\n",
    "    list years: Lista de anos de cada arquivo\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    list new_year: Lista de anos conforme o min value\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    new_year = [] \n",
    "\n",
    "    for year in years:\n",
    "        for i in year:\n",
    "            if i not in new_year:\n",
    "                new_year.append(i)\n",
    "\n",
    "    cont = 0 \n",
    "    while(len(new_year) < min_value):\n",
    "        new_year.append(new_year[cont])\n",
    "        cont+=1\n",
    "\n",
    "    new_year = sorted(new_year)\n",
    "    \n",
    "    return(new_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva de Crescimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para gerar esses plots deve ser em float o loc\n",
    "tm_series = np.array(new_loc_list) #Cria uma matriz com os valores de LOC\n",
    "\n",
    "clusters_by_time_series = {}\n",
    "\n",
    "centroids, assign, best_shift, cent_dists = ksc.ksc(tm_series, 3) # inicia o algoritmo com 3 clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if assign is not None:\n",
    "    for series, cluster in zip(tm_series, assign):\n",
    "        if cluster in clusters_by_time_series.keys():\n",
    "            clusters_by_time_series[cluster].append(series)\n",
    "        else:\n",
    "            clusters_by_time_series[cluster] = [series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster(clusters_by_time_series):\n",
    "    for cluster in clusters_by_time_series.keys():\n",
    "        figure = plt.figure()\n",
    "\n",
    "        for project_time_series in clusters_by_time_series[cluster]:\n",
    "            #if weeks is None:\n",
    "            #    weeks = [-i for i in range(len(project_time_series) - 1, -1, -1)]\n",
    "\n",
    "            project_time_series = [0 if i == 0.1 else int(i) for i in project_time_series]\n",
    "\n",
    "            years_d = create_year_serie(len(project_time_series), years)\n",
    "\n",
    "        plt.xlabel('Years')\n",
    "        plt.ylabel('Line Of Code')\n",
    "        plt.plot(years_d, project_time_series, color='black')\n",
    "        \n",
    "        #figure.savefig('curva_crescimento.png', bbox_inches='tight', format='png', dpi=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_centroid(centroids):\n",
    "    for cluster, centroid in zip(range(0, 3), centroids):\n",
    "        growth_rate = centroid[0] + centroid[-1] * 100\n",
    "        #report_file.write(str(cluster) + ': ' + str(centroid) + ' (Growth:' + str(\"{0:.2f}\".format(growth_rate)) + ')\\n')\n",
    "\n",
    "        #if weeks is None:\n",
    "        #    weeks = [-i for i in range(len(centroid) - 1, -1, -1)]\n",
    "\n",
    "        figure = plt.figure()\n",
    "        plt.xlabel('Years')\n",
    "        plt.ylabel('Average')\n",
    "        plt.plot(years_d, centroid, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in self.clusters_by_time_series.keys():\n",
    "            figure = plt.figure()\n",
    "            for project_time_series in self.clusters_by_time_series[cluster]:\n",
    "               \n",
    "                project_time_series = [0 if i == 0.1 else int(i) for i in project_time_series]\n",
    "\n",
    "                plt.plot(weeks, project_time_series, color='black')\n",
    "\n",
    "            plt.ylim([0, 475])\n",
    "            plt.xlim([-75, 3])\n",
    "            plt.xlabel('Week', fontsize=24)\n",
    "            plt.ylabel('# Newcomers', fontsize=24)\n",
    "            plt.xticks(fontsize=22)\n",
    "            plt.yticks(fontsize=22)\n",
    "\n",
    "            filename = self.images_folder + '/cluster_' + str(cluster) + '.eps'\n",
    "\n",
    "            if os.path.isfile(filename):\n",
    "                os.remove(filename)\n",
    "\n",
    "            figure.savefig(filename, bbox_inches='tight', format='eps', dpi=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_cluster(clusters_by_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_centroid(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de Arquivos 131\n",
      "\n",
      "\n",
      "Cluster 1 possui 25 arquivos, representa 19.08%\n",
      "Cluster 2 possui 106 arquivos, representa 80.92%\n"
     ]
    }
   ],
   "source": [
    "# quantidade de arquivos por cluster\n",
    "\n",
    "print(\"Quantidade de Arquivos {}\".format(len(new_loc_list)))\n",
    "print(\"\\n\")\n",
    "for i in range(len(clusters_by_time_series)):\n",
    "    print(\"Cluster {} possui {} arquivos, representa {}%\".format(i+1, len(clusters_by_time_series[i]), round((float(len(clusters_by_time_series[i])) * 100)/float(len(new_loc_list)), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Para o o google sheets entenda a entrada dos dados \n",
    "a lista de centroids deve estar ordenada.\n",
    "'''\n",
    "\n",
    "\n",
    "centroids_order = [[],[]]\n",
    "\n",
    "for i in range(len(centroids)):\n",
    "    for j in range(len(centroids[i])):\n",
    "        centroids_order[i].append(round(centroids[i][j], 3))\n",
    "\n",
    "#centroids_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
